{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.stats import beta\n",
    "import os\n",
    "import random\n",
    "\n",
    "# ============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class UserType(Enum):\n",
    "    LOYAL = 0\n",
    "    DISGRUNTLED = 1 \n",
    "    MALICIOUS = 2\n",
    "\n",
    "@dataclass\n",
    "class ChannelMetadata:\n",
    "    index: int\n",
    "    name: str\n",
    "    category: str\n",
    "    severity: float\n",
    "\n",
    "# ============================================================================\n",
    "# 2. CAUSAL DBN ENGINE\n",
    "# ============================================================================\n",
    "\n",
    "class CausalDependencyDBN:\n",
    "    def __init__(self, channels: Dict[str, ChannelMetadata]):\n",
    "        self.channels = channels\n",
    "        self.causal_parents = self._build_dynamic_graph()\n",
    "        \n",
    "        # Likelihood Parameters \n",
    "        self.params = {\n",
    "            UserType.LOYAL: {'a': 2, 'b': 12},       # Mean ~0.14 (Quiet)\n",
    "            UserType.DISGRUNTLED: {'a': 4, 'b': 6},  # Mean ~0.40 (Noisy)\n",
    "            UserType.MALICIOUS: {'a': 10, 'b': 2}    # Mean ~0.83 (High/Suspicious)\n",
    "        }\n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #5: Signal-Weighted Updates (Exfil signals get higher weight)\n",
    "        # ====================================================================\n",
    "        self.signal_weights = {\n",
    "            'logon': 1.0,\n",
    "            'device': 1.2,\n",
    "            'file': 1.66,\n",
    "            'email': 1.8,        # Higher weight for data movement\n",
    "            'exfil': 2.5,        # HIGHEST: external exfil is critical\n",
    "            'role': 1.3\n",
    "        }\n",
    "\n",
    "    def _build_dynamic_graph(self) -> Dict[int, List[int]]:\n",
    "        parents = {meta.index: [] for meta in self.channels.values()}\n",
    "        cat_indices = {cat: [] for cat in [\"Access\", \"Reconnaissance\", \"Privilege\", \"Exfiltration\"]}\n",
    "        \n",
    "        for meta in self.channels.values():\n",
    "            if meta.category in cat_indices: cat_indices[meta.category].append(meta.index)\n",
    "\n",
    "        # Kill Chain Dependencies\n",
    "        for recon in cat_indices[\"Reconnaissance\"]: parents[recon].extend(cat_indices[\"Access\"])\n",
    "        for priv in cat_indices[\"Privilege\"]: \n",
    "            parents[priv].extend(cat_indices[\"Access\"] + cat_indices[\"Reconnaissance\"])\n",
    "        for exfil in cat_indices[\"Exfiltration\"]:\n",
    "            parents[exfil].extend(cat_indices[\"Privilege\"] + cat_indices[\"Reconnaissance\"])\n",
    "            \n",
    "        return parents\n",
    "\n",
    "    def get_conditional_params(self, idx: int, val: float, parents: List[float], u_type: UserType):\n",
    "        p = self.params[u_type]\n",
    "        a, b = p['a'], p['b']\n",
    "        \n",
    "        if not parents: return a, b\n",
    "        parent_avg = np.mean(parents)\n",
    "        \n",
    "        # Malicious Causal Link: If parents are high, child becomes VERY high\n",
    "        if u_type == UserType.MALICIOUS and parent_avg > 0.5:\n",
    "            return a + 10, 1.0 \n",
    "        \n",
    "        # Loyal/Disgruntled: Weak correlation\n",
    "        return a + (parent_avg * 0.5), b\n",
    "\n",
    "    def compute_log_likelihood(self, signals: np.ndarray, user_type: UserType) -> float:\n",
    "        log_prob = 0.0\n",
    "        epsilon = 1e-9\n",
    "        for name, meta in self.channels.items():\n",
    "            idx = meta.index\n",
    "            val = np.clip(signals[idx], 0.01, 0.99)\n",
    "            p_vals = [signals[p] for p in self.causal_parents[idx]]\n",
    "            \n",
    "            a, b = self.get_conditional_params(idx, val, p_vals, user_type)\n",
    "            log_prob += np.log(beta.pdf(val, a, b) + epsilon)\n",
    "        return log_prob\n",
    "\n",
    "    def compute_threat_score(self, signals: np.ndarray) -> float:\n",
    "        score = 0.0\n",
    "        weights = 0.0\n",
    "        for name, meta in self.channels.items():\n",
    "            val = signals[meta.index]\n",
    "            w = meta.severity * (2.0 if val > 0.7 else 1.0) \n",
    "            score += val * w\n",
    "            weights += meta.severity\n",
    "        return score / weights if weights > 0 else 0\n",
    "\n",
    "\n",
    "    def compute_threat_score_enhanced(self, signals: np.ndarray, parents_high: bool = False) -> float:\n",
    "        \"\"\"Enhanced threat score with causal chain amplification.\"\"\"\n",
    "        score = 0.0\n",
    "        weights = 0.0\n",
    "        \n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #3: Causal Chain Amplification in Threat Scoring\n",
    "        # ====================================================================\n",
    "        # Higher weight if parent signals (reconnaissance, privilege escalation) are high\n",
    "        chain_boost = 1.33 if parents_high else 1.0\n",
    "        \n",
    "        for name, meta in self.channels.items():\n",
    "            val = signals[meta.index]\n",
    "            # Exfiltration category gets highest weight (email, exfil)\n",
    "            is_exfil = 'exfil' in name.lower() or 'email' in name.lower()\n",
    "            exfil_weight = 2.5 if is_exfil else 1.0\n",
    "            \n",
    "            w = meta.severity * exfil_weight * chain_boost\n",
    "            if val > 0.7:\n",
    "                w *= 2.0  # High signal amplification\n",
    "            elif val > 0.5:\n",
    "                w *= 1.5  # Medium amplification\n",
    "                \n",
    "            score += val * w\n",
    "            weights += meta.severity * exfil_weight\n",
    "        \n",
    "        return score / weights if weights > 0 else 0\n",
    "\n",
    "# ============================================================================\n",
    "# 3. BYZANTINE COMMITTEE\n",
    "# ============================================================================\n",
    "\n",
    "class ByzantineCommittee:\n",
    "    def __init__(self, channels, n_members=5, f_traitors=1):\n",
    "        self.dbn = CausalDependencyDBN(channels)\n",
    "        self.n_members = n_members\n",
    "        self.f_traitors = f_traitors\n",
    "        self.gamma = 0.15 # SACC Clipping Bound\n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #1: Adaptive Detection Thresholds (Lower for early detection)\n",
    "        # ====================================================================\n",
    "        self.detection_threshold_flag = 0.75      # Flag (LOWERED from 1.0)\n",
    "        self.detection_threshold_escalate = 1.66  # Escalate (LOWERED from 2.0)\n",
    "        self.detection_threshold_suspend = 2.5   # Suspend (LOWERED from 3.0)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #2: Faster Belief Convergence (Higher learning rate)\n",
    "        # ====================================================================\n",
    "        self.belief_learning_rate = 1.25  # Accelerated updates (was ~1.0)\n",
    "        \n",
    "        self.user_beliefs = {}\n",
    "        self.belief_history = {}\n",
    "        \n",
    "        self.transitions = {\n",
    "            UserType.LOYAL: {UserType.LOYAL: 0.99, UserType.DISGRUNTLED: 0.01, UserType.MALICIOUS: 0.0},\n",
    "            UserType.DISGRUNTLED: {UserType.LOYAL: 0.05, UserType.DISGRUNTLED: 0.90, UserType.MALICIOUS: 0.05},\n",
    "            UserType.MALICIOUS: {UserType.LOYAL: 0.0, UserType.DISGRUNTLED: 0.0, UserType.MALICIOUS: 1.0}\n",
    "        }\n",
    "\n",
    "    def initialize_user(self, uid):\n",
    "        self.user_beliefs[uid] = {UserType.LOYAL: 0.9, UserType.DISGRUNTLED: 0.09, UserType.MALICIOUS: 0.01}\n",
    "        self.belief_history[uid] = {\"system\": [], \"anchor\": [], \"byzantine\": [], \"raw_mean\": []}\n",
    "\n",
    "    def _bayes_update(self, prior, signals):\n",
    "        pred = {t: sum(prior[s] * self.transitions[s][t] for s in UserType) for t in UserType}\n",
    "        log_likes = {t: self.dbn.compute_log_likelihood(signals, t) for t in UserType}\n",
    "        max_l = max(log_likes.values())\n",
    "        likes = {t: np.exp(l - max_l) for t, l in log_likes.items()}\n",
    "        post_un = {t: pred[t] * likes[t] for t in UserType}\n",
    "        norm = sum(post_un.values()) or 1e-9\n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #5: Signal-Weighted Bayesian Updates\n",
    "        # Apply higher weight to exfiltration signals (email, exfil)\n",
    "        # ====================================================================\n",
    "        # Apply learning rate acceleration and signal weights to posterior\n",
    "        post_weighted = {}\n",
    "        for t in UserType:\n",
    "            weighted_val = v = post_un[t]\n",
    "            # Amplify malicious belief if high-confidence exfil signals detected\n",
    "            if t == UserType.MALICIOUS and np.max(signals) > 0.7:\n",
    "                weighted_val = v * (1.0 + self.belief_learning_rate * 0.3)\n",
    "            post_weighted[t] = weighted_val\n",
    "        \n",
    "        norm = sum(post_weighted.values()) or 1e-9\n",
    "        return {t: v/norm for t, v in post_weighted.items()}\n",
    "\n",
    "    def certify(self, uid, signals):\n",
    "        if uid not in self.user_beliefs: self.initialize_user(uid)\n",
    "        \n",
    "        # 1. Anchor (Truth)\n",
    "        anchor_dist = self._bayes_update(self.user_beliefs[uid], signals)\n",
    "        anchor_mal = anchor_dist[UserType.MALICIOUS]\n",
    "        \n",
    "        # 2. Honest Reports\n",
    "        reports = [np.clip(anchor_mal + random.uniform(-0.03, 0.03), 0, 1) for _ in range(self.n_members - self.f_traitors)]\n",
    "        \n",
    "        # 3. Traitor Reports\n",
    "        # Visualization User (0): Aggressive suppression to visualize the gap\n",
    "        # Others: \"Little is Enough\" attack to evade clipping\n",
    "        if uid == 0:\n",
    "            traitor_val = 0.05\n",
    "        else:\n",
    "            traitor_val = max(0.0, anchor_mal - 0.25)\n",
    "            \n",
    "        reports.extend([traitor_val] * self.f_traitors)\n",
    "        \n",
    "        # 4. SACC Aggregation\n",
    "        clipped = []\n",
    "        for r in reports:\n",
    "            diff = r - anchor_mal\n",
    "            if abs(diff) > self.gamma:\n",
    "                clipped.append(anchor_mal + (np.sign(diff) * self.gamma))\n",
    "            else:\n",
    "                clipped.append(r)\n",
    "        \n",
    "        robust_mal = np.mean(clipped)\n",
    "        \n",
    "        # Update State\n",
    "        rem = 1.0 - robust_mal\n",
    "        self.user_beliefs[uid] = {\n",
    "            UserType.LOYAL: rem * 0.9, UserType.DISGRUNTLED: rem * 0.1, UserType.MALICIOUS: robust_mal\n",
    "        }\n",
    "        \n",
    "        # Log History\n",
    "        h = self.belief_history[uid]\n",
    "        h[\"system\"].append(robust_mal)\n",
    "        h[\"anchor\"].append(anchor_mal)\n",
    "        h[\"byzantine\"].append(traitor_val)\n",
    "        h[\"raw_mean\"].append(np.mean(reports))\n",
    "        \n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #4: Multi-Stage Detection (Detect at escalate + suspend)\n",
    "        # ====================================================================\n",
    "        # Apply adaptive thresholds for early detection\n",
    "        threat_score = robust_mal * 4.0  # Scale to ITS range [0, 4]\n",
    "        detection_status = 'normal'\n",
    "        \n",
    "        if threat_score >= self.detection_threshold_suspend:\n",
    "            detection_status = 'SUSPEND'\n",
    "        elif threat_score >= self.detection_threshold_escalate:\n",
    "            detection_status = 'ESCALATE'  # Early detection at escalate level\n",
    "        elif threat_score >= self.detection_threshold_flag:\n",
    "            detection_status = 'FLAG'\n",
    "        \n",
    "        # Store detection metadata for analysis\n",
    "        self.user_beliefs[uid]['_threat_score'] = threat_score\n",
    "        self.user_beliefs[uid]['_detection_status'] = detection_status\n",
    "\n",
    "        return robust_mal\n",
    "\n",
    "# ============================================================================\n",
    "# 4. SIMULATION LOOP (Hybrid)\n",
    "# ============================================================================\n",
    "class ByzantineSimulation:\n",
    "    def __init__(self, policy_file):\n",
    "        self.channels = self._load_policies(policy_file)\n",
    "        self.committee = ByzantineCommittee(self.channels)\n",
    "        self.n_channels = len(self.channels)\n",
    "\n",
    "    def _load_policies(self, fpath):\n",
    "        with open(fpath) as f: policies = json.load(f)\n",
    "        temp = {}\n",
    "        for p in policies:\n",
    "            cn = p['signal_channel']\n",
    "            if cn not in temp: \n",
    "                temp[cn] = ChannelMetadata(len(temp), cn, p.get('category', 'Activity'), p.get('severity', 0.5))\n",
    "        return temp\n",
    "\n",
    "    def _generate_signals(self, u_type, t, is_malicious, uid):\n",
    "        signals = np.random.beta(2, 12, size=self.n_channels)\n",
    "\n",
    "        if is_malicious:\n",
    "            # A. VISUALIZATION USER (0)\n",
    "            if uid == 0:\n",
    "                if t > 50:\n",
    "                    for m in self.channels.values():\n",
    "                        signals[m.index] = np.random.beta(15, 2) \n",
    "                    return np.clip(signals, 0.01, 0.99)\n",
    "                \n",
    "            # B. OTHERS (Standard Attacker)\n",
    "            else:\n",
    "                if random.random() < 0.15: return np.clip(signals * 0.5, 0.01, 0.99)\n",
    "                if t > 50: \n",
    "                    # FIX: Boost ALL stages of the kill chain, not just exfil\n",
    "                    # This allows the DBN to see the full causal path\n",
    "                    for m in self.channels.values():\n",
    "                        if m.category == \"Access\":\n",
    "                            signals[m.index] = np.random.beta(12, 4) # Suspicious Access\n",
    "                        elif m.category in [\"Exfiltration\", \"Privilege\"]:\n",
    "                            signals[m.index] = np.random.beta(10, 2) # High Impact\n",
    "        \n",
    "        elif u_type == UserType.DISGRUNTLED:\n",
    "            n_spikes = random.randint(1, 3)\n",
    "            indices = random.sample(range(self.n_channels), n_spikes)\n",
    "            for idx in indices:\n",
    "                signals[idx] = np.random.beta(4, 6)\n",
    "        elif u_type == UserType.LOYAL and random.random() < 0.05:  # 5% of benign timesteps\n",
    "            # Simulate a legitimate but suspicious activity (e.g., batch job)\n",
    "            idx = random.randint(0, len(self.channels)-1)\n",
    "            signals[idx] = np.random.beta(15, 3)  # High activity\n",
    "        elif u_type == UserType.LOYAL and random.random() < 0.02:\n",
    "            idx = random.randint(0, self.n_channels-1)\n",
    "            signals[idx] = 0.85\n",
    "\n",
    "        return np.clip(signals, 0.01, 0.99)\n",
    "\n",
    "    def run(self, n_users=100, pct_mal=0.15, horizon=90):\n",
    "        n_mal = int(n_users * pct_mal)\n",
    "        results = {\"detected\": [], \"false_positives\": [], \"undetected\": [], \"hist\": {}}\n",
    "        THRESHOLD = 0.88\n",
    "\n",
    "        for uid in range(n_users):\n",
    "            is_mal = uid < n_mal\n",
    "            u_type = UserType.LOYAL\n",
    "            self.committee.initialize_user(uid)\n",
    "            results[\"hist\"][uid] = {\"type\": [], \"causal_score\": []}\n",
    "            detected = False\n",
    "\n",
    "            for t in range(horizon):\n",
    "                if uid == 0:\n",
    "                    if t > 50: u_type = UserType.MALICIOUS\n",
    "                    elif t > 30: u_type = UserType.DISGRUNTLED\n",
    "                else:\n",
    "                    if is_mal and t > 50: u_type = UserType.MALICIOUS\n",
    "                    elif not is_mal and t > 30 and random.random() < 0.02: u_type = UserType.DISGRUNTLED\n",
    "                \n",
    "                results[\"hist\"][uid][\"type\"].append(u_type.value)\n",
    "                signals = self._generate_signals(u_type, t, is_mal, uid)\n",
    "                p_mal = self.committee.certify(uid, signals)\n",
    "                threat = self.committee.dbn.compute_threat_score(signals)\n",
    "                \n",
    "                results[\"hist\"][uid][\"causal_score\"].append(threat)\n",
    "                risk = (p_mal * 0.4) + (threat * 0.6)\n",
    "                # NEW: Add realistic measurement/monitoring noise for benign users\n",
    "                #if not is_mal and random.random() < 0.08:  # 8% chance per benign user per timestep\n",
    "                #    risk += random.uniform(0.05, 0.15)  # Boost risk by 5-15%\n",
    "\n",
    "\n",
    "                if risk > THRESHOLD and not detected:\n",
    "                    detected = True\n",
    "                    if is_mal: results[\"detected\"].append(uid)\n",
    "                    else: results[\"false_positives\"].append(uid)\n",
    "            \n",
    "            if is_mal and not detected: results[\"undetected\"].append(uid)\n",
    "\n",
    "        return results\n",
    "\n",
    "# ============================================================================\n",
    "# 5. VISUALIZATION\n",
    "# ============================================================================\n",
    "\n",
    "class FullVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_combined_dashboard(res, committee, n_users, uid_malicious=0):\n",
    "        \"\"\"Combined 2x2 dashboard with all 4 visualizations + metrics printed as text.\"\"\"\n",
    "        fig = plt.figure(figsize=(18, 14))\n",
    "        gs = gridspec.GridSpec(2, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "        # ===== Panel 1: Type Evolution (Top-Left) =====\n",
    "        ax1 = plt.subplot(gs[0, 0])\n",
    "        ax1.set_title(\"1. User Type Evolution (Ground Truth)\", fontweight='bold', fontsize=12)\n",
    "        ax1.set_yticks([0, 1, 2])\n",
    "        ax1.set_yticklabels(['LOY', 'DIS', 'MAL'])\n",
    "        ax1.set_xlabel(\"Time Step\")\n",
    "        for uid in list(res[\"detected\"][:3]) + list(res[\"undetected\"][:3]):\n",
    "            color = 'red' if uid in res[\"detected\"] else 'orange'\n",
    "            ax1.plot(res[\"hist\"][uid][\"type\"], color=color, alpha=0.6, linewidth=1.5)\n",
    "        for uid in range(n_users - 3, n_users):\n",
    "            ax1.plot(res[\"hist\"][uid][\"type\"], color='green', alpha=0.3, linewidth=0.8)\n",
    "        ax1.grid(True, alpha=0.2)\n",
    "        # ADD LABEL (a) BELOW X-AXIS\n",
    "        ax1.text(0.5, -0.18, '(a)',\n",
    "                transform=ax1.transAxes,\n",
    "                fontsize=13, fontweight='bold',\n",
    "                va='top', ha='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "        # ===== Panel 2: Causal Kill Chain Evidence (Top-Right) =====\n",
    "        ax2 = plt.subplot(gs[0, 1])\n",
    "        ax2.set_title(\"2. Causal Kill Chain Evidence\", fontweight='bold', fontsize=12)\n",
    "        ax2.set_xlabel(\"Time Step\")\n",
    "        ax2.set_ylabel(\"Causal Score\")\n",
    "        for uid in res[\"hist\"]:\n",
    "            scores = res[\"hist\"][uid][\"causal_score\"]\n",
    "            if uid in res[\"detected\"][:5]:\n",
    "                ax2.plot(scores, color='red', alpha=0.5, linewidth=1.5)\n",
    "            elif uid > n_users - 5:\n",
    "                ax2.plot(scores, color='green', alpha=0.3, linewidth=0.8)\n",
    "        ax2.grid(True, alpha=0.2)\n",
    "        # ADD LABEL (b) BELOW X-AXIS\n",
    "        ax2.text(0.5, -0.18, '(b)',\n",
    "                transform=ax2.transAxes,\n",
    "                fontsize=13, fontweight='bold',\n",
    "                va='top', ha='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "        # ===== Panel 3: System Belief Convergence (Bottom-Left) =====\n",
    "        ax3 = plt.subplot(gs[1, 0])\n",
    "        ax3.set_title(\"3. System Belief Convergence\", fontweight='bold', fontsize=12)\n",
    "        ax3.set_xlabel(\"Time Step\")\n",
    "        ax3.set_ylabel(\"Belief Score\")\n",
    "        ax3.axhline(0.75, color='black', linestyle='--', linewidth=1, label='Detection Threshold')\n",
    "        for uid in res[\"hist\"]:\n",
    "            beliefs = committee.belief_history[uid][\"system\"]\n",
    "            if uid in res[\"detected\"][:5]:\n",
    "                ax3.plot(beliefs, color='red', alpha=0.7, linewidth=1.5)\n",
    "            elif uid in res[\"false_positives\"][:5]:\n",
    "                ax3.plot(beliefs, color='blue', alpha=0.6, linewidth=1.2)\n",
    "            elif uid > n_users - 5:\n",
    "                ax3.plot(beliefs, color='green', alpha=0.2, linewidth=0.8)\n",
    "        ax3.legend(loc='best', fontsize=9)\n",
    "        ax3.grid(True, alpha=0.2)\n",
    "        # ADD LABEL (c) BELOW X-AXIS\n",
    "        ax3.text(0.5, -0.18, '(c)',\n",
    "                transform=ax3.transAxes,\n",
    "                fontsize=13, fontweight='bold',\n",
    "                va='top', ha='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "        # ===== Panel 4: SACC Robustness (Bottom-Right) =====\n",
    "        ax4 = plt.subplot(gs[1, 1])\n",
    "        ax4.set_title(\"4. SACC Defense - Byzantine Resilience\", fontweight='bold', fontsize=12)\n",
    "        ax4.set_xlabel(\"Time Step\")\n",
    "        ax4.set_ylabel(\"Belief Score\")\n",
    "\n",
    "        hist = committee.belief_history[uid_malicious]\n",
    "        ax4.plot(hist[\"anchor\"], color='blue', linestyle='--', label='Anchor (Truth)', linewidth=2)\n",
    "        ax4.plot(hist[\"byzantine\"], color='red', linestyle=':', label='Traitor (Suppression)', linewidth=1.5)\n",
    "        ax4.plot(hist[\"raw_mean\"], color='orange', linestyle='-.', label='Naive Mean', alpha=0.7, linewidth=1.5)\n",
    "        ax4.plot(hist[\"system\"], color='green', label='SACC Belief (Robust)', linewidth=2.5)\n",
    "        ax4.axhline(0.75, color='grey', linestyle='--', alpha=0.5)\n",
    "        ax4.fill_between(range(len(hist[\"system\"])), hist[\"raw_mean\"], hist[\"system\"], \n",
    "                        color='green', alpha=0.1, label='SACC Protection')\n",
    "        ax4.legend(loc='best', fontsize=9)\n",
    "        ax4.grid(True, alpha=0.2)\n",
    "        # ADD LABEL (d) BELOW X-AXIS\n",
    "        ax4.text(0.5, -0.18, '(d)',\n",
    "                transform=ax4.transAxes,\n",
    "                fontsize=13, fontweight='bold',\n",
    "                va='top', ha='center',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "        plt.suptitle(\"Byzantine-Resilient IAM Certification System - 2x2 Dashboard\", \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        plt.rcParams['axes.linewidth'] = 1.5\n",
    "        plt.rcParams['axes.labelcolor'] = '#333333'\n",
    "        plt.rcParams['xtick.labelsize'] = 11\n",
    "        plt.rcParams['ytick.labelsize'] = 11\n",
    "        plt.rcParams['xtick.color'] = '#333333'\n",
    "        plt.rcParams['ytick.color'] = '#333333'\n",
    "        plt.rcParams['grid.color'] = '#666666'\n",
    "        plt.rcParams['grid.alpha'] = 0.4\n",
    "\n",
    "        plt.savefig(\"dbn_dashboard_combined.png\", dpi=100, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # ===== PRINT METRICS AS TEXT =====\n",
    "        tp = len(res[\"detected\"])\n",
    "        fp = len(res[\"false_positives\"])\n",
    "        fn = len(res[\"undetected\"])\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"DETECTION METRICS\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total Users:          {n_users}\")\n",
    "        print(f\"True Positives (TP):  {tp}\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"False Negatives (FN): {fn}\")\n",
    "        print(f\"\\nPrecision:  {prec:.4f}\")\n",
    "        print(f\"Recall:     {rec:.4f}\")\n",
    "        print(f\"F1 Score:   {f1:.4f}\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_main_dashboard(res, committee, n_users):\n",
    "        \"\"\"Legacy method - now calls the combined dashboard.\"\"\"\n",
    "        FullVisualizer.plot_combined_dashboard(res, committee, n_users, uid_malicious=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_sacc_robustness(committee, uid_malicious):\n",
    "        hist = committee.belief_history[uid_malicious]\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(hist[\"anchor\"], color='blue', linestyle='--', label='Anchor (Truth)', linewidth=2)\n",
    "        plt.plot(hist[\"byzantine\"], color='red', linestyle=':', label='Traitor (Suppression)', linewidth=1.5)\n",
    "        plt.plot(hist[\"raw_mean\"], color='orange', linestyle='-.', label='Naive Mean (Vulnerable)', alpha=0.7)\n",
    "        plt.plot(hist[\"system\"], color='green', label='SACC Belief (Robust)', linewidth=2.5)\n",
    "        \n",
    "        plt.title(f\"SACC Defense Protection Zone)\", fontsize=14)\n",
    "        plt.axhline(0.75, color='grey', linestyle='--')\n",
    "        plt.fill_between(range(len(hist[\"system\"])), hist[\"raw_mean\"], hist[\"system\"], color='green', alpha=0.1, label='SACC Protection')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.savefig(\"sacc_robustness.png\")\n",
    "        plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(\"policies.json\"):\n",
    "        with open(\"policies.json\", \"w\") as f:\n",
    "            json.dump([\n",
    "                {\"signal_channel\": \"s_logon\", \"category\": \"Access\", \"severity\": 0.6},\n",
    "                {\"signal_channel\": \"s_file\", \"category\": \"Reconnaissance\", \"severity\": 0.7},\n",
    "                {\"signal_channel\": \"s_role\", \"category\": \"Privilege\", \"severity\": 0.9},\n",
    "                {\"signal_channel\": \"s_exfil\", \"category\": \"Exfiltration\", \"severity\": 0.8}\n",
    "            ], f)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"RUNNING HYBRID SIMULATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    sim = ByzantineSimulation(\"policies.json\")\n",
    "    results = sim.run(n_users=100, pct_mal=0.15, horizon=90)\n",
    "    \n",
    "    FullVisualizer.plot_main_dashboard(results, sim.committee, 100)\n",
    "    \n",
    "    # Plot SACC Robustness for User 0 (Guaranteed Attacker)\n",
    "    #FullVisualizer.plot_sacc_robustness(sim.committee, 0)\n",
    "        \n",
    "    print(\"\\nâœ“ Process Complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
