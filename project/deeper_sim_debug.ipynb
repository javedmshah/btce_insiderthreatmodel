{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ae6f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy.stats import beta\n",
    "import os\n",
    "import random\n",
    "\n",
    "# ============================================================================\n",
    "# 1. CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "class UserType(Enum):\n",
    "    LOYAL = 0\n",
    "    DISGRUNTLED = 1 \n",
    "    MALICIOUS = 2\n",
    "\n",
    "@dataclass\n",
    "class ChannelMetadata:\n",
    "    index: int\n",
    "    name: str\n",
    "    category: str\n",
    "    severity: float\n",
    "\n",
    "P_MAL = 0.3\n",
    "THREAT = 0.7\n",
    "TRIGGER_DAY = 20\n",
    "THRESHOLD = 0.5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b582530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 2. CAUSAL DBN ENGINE\n",
    "# ============================================================================\n",
    "class CausalDependencyDBN:\n",
    "    def __init__(self, channels: Dict[str, ChannelMetadata]):\n",
    "        self.channels = channels\n",
    "        self.causal_parents = self._build_dynamic_graph()\n",
    "        \n",
    "        # Likelihood Parameters \n",
    "        self.params = {\n",
    "            UserType.LOYAL: {'a': 2, 'b': 12},       # Mean ~0.14 (Quiet)\n",
    "            UserType.DISGRUNTLED: {'a': 4, 'b': 6},  # Mean ~0.40 (Noisy)\n",
    "            UserType.MALICIOUS: {'a': 10, 'b': 2}    # Mean ~0.83 (High/Suspicious)\n",
    "        }\n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #5: Signal-Weighted Updates (Exfil signals get higher weight)\n",
    "        # ====================================================================\n",
    "        self.signal_weights = {\n",
    "            'logon': 1.0,\n",
    "            'device': 1.2,\n",
    "            'file': 1.66,\n",
    "            'email': 1.8,        # Higher weight for data movement\n",
    "            'exfil': 2.5,        # HIGHEST: external exfil is critical\n",
    "            'role': 1.3\n",
    "        }\n",
    "\n",
    "    def _build_dynamic_graph(self) -> Dict[int, List[int]]:\n",
    "        parents = {meta.index: [] for meta in self.channels.values()}\n",
    "        cat_indices = {cat: [] for cat in [\"Access\", \"Reconnaissance\", \"Privilege\", \"Exfiltration\"]}\n",
    "        \n",
    "        for meta in self.channels.values():\n",
    "            if meta.category in cat_indices: cat_indices[meta.category].append(meta.index)\n",
    "\n",
    "        # Kill Chain Dependencies\n",
    "        for recon in cat_indices[\"Reconnaissance\"]: parents[recon].extend(cat_indices[\"Access\"])\n",
    "        for priv in cat_indices[\"Privilege\"]: \n",
    "            parents[priv].extend(cat_indices[\"Access\"] + cat_indices[\"Reconnaissance\"])\n",
    "        for exfil in cat_indices[\"Exfiltration\"]:\n",
    "            parents[exfil].extend(cat_indices[\"Privilege\"] + cat_indices[\"Reconnaissance\"])\n",
    "            \n",
    "        return parents\n",
    "\n",
    "    def get_conditional_params(self, idx: int, val: float, parents: List[float], u_type: UserType):\n",
    "        p = self.params[u_type]\n",
    "        a, b = p['a'], p['b']\n",
    "        \n",
    "        if not parents: return a, b\n",
    "        parent_avg = np.mean(parents)\n",
    "        \n",
    "        # Malicious Causal Link: If parents are high, child becomes VERY high\n",
    "        if u_type == UserType.MALICIOUS and parent_avg > 0.5:\n",
    "            return a + 10, 1.0 \n",
    "        \n",
    "        # Loyal/Disgruntled: Weak correlation\n",
    "        return a + (parent_avg * 0.5), b\n",
    "\n",
    "    def compute_log_likelihood(self, signals: np.ndarray, user_type: UserType) -> float:\n",
    "        log_prob = 0.0\n",
    "        epsilon = 1e-9\n",
    "        for name, meta in self.channels.items():\n",
    "            idx = meta.index\n",
    "            val = np.clip(signals[idx], 0.01, 0.99)\n",
    "            p_vals = [signals[p] for p in self.causal_parents[idx]]\n",
    "            \n",
    "            a, b = self.get_conditional_params(idx, val, p_vals, user_type)\n",
    "            log_prob += np.log(beta.pdf(val, a, b) + epsilon)\n",
    "        return log_prob\n",
    "\n",
    "    def compute_threat_score(self, signals: np.ndarray) -> float:\n",
    "        score = 0.0\n",
    "        weights = 0.0\n",
    "        for name, meta in self.channels.items():\n",
    "            val = signals[meta.index]\n",
    "            w = meta.severity * (2.0 if val > 0.7 else 1.0) \n",
    "            score += val * w\n",
    "            weights += meta.severity\n",
    "        return score / weights if weights > 0 else 0\n",
    "\n",
    "\n",
    "    def compute_threat_score_enhanced(self, signals: np.ndarray, parents_high: bool = False) -> float:\n",
    "        \"\"\"Enhanced threat score with causal chain amplification.\"\"\"\n",
    "        score = 0.0\n",
    "        weights = 0.0\n",
    "        \n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #3: Causal Chain Amplification in Threat Scoring\n",
    "        # ====================================================================\n",
    "        # Higher weight if parent signals (reconnaissance, privilege escalation) are high\n",
    "        chain_boost = 1.33 if parents_high else 1.0\n",
    "        \n",
    "        for name, meta in self.channels.items():\n",
    "            val = signals[meta.index]\n",
    "            # Exfiltration category gets highest weight (email, exfil)\n",
    "            # Use configured signal_weights based on channel name\n",
    "            lower_name = name.lower()\n",
    "            channel_key = None\n",
    "            for key in self.signal_weights.keys():\n",
    "                if key in lower_name:\n",
    "                    channel_key = key\n",
    "                    break\n",
    "            if channel_key is None:\n",
    "                # Fallback category if nothing matched (keeps behavior sane)\n",
    "                channel_key = 'logon'\n",
    "\n",
    "            exfil_weight = self.signal_weights.get(channel_key, 1.0)\n",
    "\n",
    "            \n",
    "            w = meta.severity * exfil_weight * chain_boost\n",
    "            if val > 0.7:\n",
    "                w *= 2.0  # High signal amplification\n",
    "            elif val > 0.5:\n",
    "                w *= 1.5  # Medium amplification\n",
    "                \n",
    "            score += val * w\n",
    "            weights += meta.severity * exfil_weight\n",
    "        \n",
    "        return score / weights if weights > 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "561ccfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 3. GAME-THEORETIC USER AGENT\n",
    "# ============================================================================\n",
    "# ============================================================================\n",
    "# 3. GAME-THEORETIC USER AGENT  (Option B: loyalty via utilities, no hard guard)\n",
    "# ============================================================================\n",
    "\n",
    "class UserAgent:\n",
    "    \"\"\"Game-theoretic user that optimizes utility function U_byz with heterogeneous, partially irrational agents.\"\"\"\n",
    "    def __init__(self, uid: int, user_type: UserType, committee):\n",
    "        self.uid = uid\n",
    "        self.type = user_type          # underlying (baseline) type\n",
    "        self.committee = committee\n",
    "        self.time = 0\n",
    "        \n",
    "        # Utility parameters (θ1, θ2, θ3, C)\n",
    "        # θ1: trust payoff when certified as non-malicious\n",
    "        # θ2: reconnaissance payoff\n",
    "        # θ3: weaponization/exfil payoff\n",
    "        # C : cost of detection\n",
    "        self.theta = {\n",
    "            # Loyal users: value trust, no real payoff for bad behavior, high cost of detection\n",
    "            UserType.LOYAL: {\n",
    "                'theta1': 2.0,\n",
    "                'theta2': 0.0,\n",
    "                'theta3': 0.0,\n",
    "                'C': 10.0\n",
    "            },\n",
    "            # Disgruntled: some value from probing/weaponizing, still somewhat afraid of detection\n",
    "            UserType.DISGRUNTLED: {\n",
    "                'theta1': 1.5,\n",
    "                'theta2': 0.5,\n",
    "                'theta3': 1.0,\n",
    "                'C': 8.0\n",
    "            },\n",
    "            # Malicious: high reward for attack, lower fear of detection\n",
    "            UserType.MALICIOUS: {\n",
    "                'theta1': 0.0,\n",
    "                'theta2': 1.0,\n",
    "                'theta3': 8.0,\n",
    "                'C': 1.5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Action space: [NORMAL, RECON, WEAPONIZE, EXFILTRATE]\n",
    "        self.actions = {\n",
    "            'NORMAL':     {'cost': 0.0, 'signal_boost': 0.0},\n",
    "            'RECON':      {'cost': 0.2, 'signal_boost': 0.3},\n",
    "            'WEAPONIZE':  {'cost': 0.5, 'signal_boost': 0.6},\n",
    "            'EXFILTRATE': {'cost': 0.8, 'signal_boost': 0.9}\n",
    "        }\n",
    "        \n",
    "        self.current_action = 'NORMAL'\n",
    "        self.utility_history = []\n",
    "        self.action_history = []\n",
    "      \n",
    "        # --------------------------------------------------------------------\n",
    "        # Heterogeneity: risk tolerance, greed, and bounded rationality\n",
    "        # --------------------------------------------------------------------\n",
    "        # Risk tolerance rescales the perceived detection cost C.\n",
    "        # Greed factor rescales the payoff for recon/weaponize/exfil.\n",
    "        # Beta controls how \"rational\" the softmax choice is.\n",
    "        if self.type == UserType.MALICIOUS:\n",
    "            # Malicious users skew more reckless and greedy\n",
    "            self.risk_tolerance = np.random.beta(1.5, 3.0)   # more mass on higher risk\n",
    "            self.greed_factor   = float(np.random.lognormal(mean=0.5, sigma=0.7))\n",
    "            self.beta           = float(np.random.choice([0.5, 1.0, 2.5], p=[0.3, 0.5, 0.2]))\n",
    "        elif self.type == UserType.DISGRUNTLED:\n",
    "            self.risk_tolerance = np.random.beta(2.0, 4.0)\n",
    "            self.greed_factor   = float(np.random.lognormal(mean=0.2, sigma=0.5))\n",
    "            self.beta           = float(np.random.choice([0.7, 1.5, 3.0], p=[0.4, 0.4, 0.2]))\n",
    "        else:\n",
    "            # Loyal users are mostly cautious and near-deterministic\n",
    "            self.risk_tolerance = np.random.beta(4.0, 2.0)\n",
    "            self.greed_factor   = 1.0\n",
    "            self.beta           = 4.0  # almost argmax (very sharp softmax)\n",
    "        \n",
    "        # A subset of malicious users are explicitly \"greedy\" and will sometimes exfiltrate\n",
    "        self.is_greedy         = (self.type == UserType.MALICIOUS) and (np.random.rand() < 0.9)\n",
    "        self.greedy_exfil_prob = 0.9  # chance to override and exfiltrate when greedy\n",
    "        \n",
    "    def choose_action(self, current_belief: Dict[UserType, float], last_detection: str) -> str:\n",
    "        \"\"\"\n",
    "        Recommend Action: User chooses action to optimize U_byz\n",
    "        using heterogeneous risk/greed and bounded rationality (softmax).\n",
    "        \n",
    "        NOTE (Option B): There is NO early return for LOYAL here.\n",
    "        Loyalty is encoded in θ and C, so loyal agents nearly always prefer NORMAL,\n",
    "        but still go through the same logic.\n",
    "        \"\"\"\n",
    "        # Logical time counter (used for debugging / analysis if needed)\n",
    "        if not hasattr(self, \"time\"):\n",
    "            self.time = 0\n",
    "        self.time += 1\n",
    "\n",
    "        # Get current malicious belief\n",
    "        p_mal = current_belief.get(UserType.MALICIOUS, 0.0)\n",
    "\n",
    "        # Compute expected utility for each action\n",
    "        utilities = {}\n",
    "        for action, params in self.actions.items():\n",
    "            # Expected payoff components\n",
    "            trust_payoff = 0.0\n",
    "            recon_payoff = 0.0\n",
    "            weapon_payoff = 0.0\n",
    "\n",
    "            # θ1: Trust payoff (certified as non-malicious)\n",
    "            certified = (p_mal < 0.3)  # Simplified certification condition\n",
    "            if certified:\n",
    "                trust_payoff = self.theta[self.type]['theta1']\n",
    "\n",
    "            # θ2: Reconnaissance payoff (if performing RECON)\n",
    "            if action == 'RECON' and p_mal < 0.5:\n",
    "                recon_payoff = self.theta[self.type]['theta2']\n",
    "\n",
    "            # θ3: Weaponization payoff (if performing WEAPONIZE or EXFILTRATE)\n",
    "            if action in ['WEAPONIZE', 'EXFILTRATE'] and p_mal < 0.7:\n",
    "                weapon_payoff = self.theta[self.type]['theta3']\n",
    "\n",
    "            # Greedy / opportunistic attackers over-weight recon/weapon payoffs\n",
    "            if self.type in [UserType.DISGRUNTLED, UserType.MALICIOUS]:\n",
    "                recon_payoff  *= self.greed_factor\n",
    "                weapon_payoff *= self.greed_factor\n",
    "\n",
    "            # C: Cost of detection (scaled by user-specific risk tolerance)\n",
    "            detection_risk = 0.0\n",
    "            if action == 'RECON':\n",
    "                detection_risk = p_mal * 0.3\n",
    "            elif action == 'WEAPONIZE':\n",
    "                detection_risk = p_mal * 0.6\n",
    "            elif action == 'EXFILTRATE':\n",
    "                detection_risk = p_mal * 0.9\n",
    "\n",
    "            base_C      = self.theta[self.type]['C']\n",
    "            effective_C = base_C * float(self.risk_tolerance)\n",
    "            detection_cost = detection_risk * effective_C\n",
    "\n",
    "            # Utility: U_byz(a_u, θ) = θ1*1_certified + θ2*1_recon + θ3*1_weapon\n",
    "            #                         - C_eff*1_detected - action_cost\n",
    "            utility = trust_payoff + recon_payoff + weapon_payoff - detection_cost - params['cost']\n",
    "\n",
    "            # Strategic considerations based on detection status\n",
    "            if last_detection == 'SUSPEND' and action != 'NORMAL':\n",
    "                utility -= 5.0  # Strong disincentive after suspension\n",
    "\n",
    "            utilities[action] = utility\n",
    "\n",
    "        # Deterministic best action, i.e. what a perfectly rational agent would do\n",
    "        # (kept for potential debugging / analysis)\n",
    "        deterministic_best_action  = max(utilities, key=utilities.get)\n",
    "        deterministic_best_utility = utilities[deterministic_best_action]\n",
    "        exfil_utility              = utilities.get('EXFILTRATE', None)\n",
    "\n",
    "        # Optional greedy override: some malicious users just go for EXFILTRATE\n",
    "        if self.is_greedy and self.type == UserType.MALICIOUS and last_detection != 'SUSPEND':\n",
    "            if np.random.rand() < self.greedy_exfil_prob:\n",
    "                best_action  = 'EXFILTRATE'\n",
    "                best_utility = utilities.get('EXFILTRATE', -float('inf'))\n",
    "                self.current_action = best_action\n",
    "                self.utility_history.append(best_utility)\n",
    "                self.action_history.append(best_action)\n",
    "                print(f\"[DEBUG][uid={self.uid}] GREEDY EXFIL\")\n",
    "                print(f\"  t={self.time}, p_mal={p_mal:.3f}, beta={self.beta:.2f}\")\n",
    "                print(f\"  U_exfil={exfil_utility:.3f}, U_best={deterministic_best_utility:.3f}\")\n",
    "                print(f\"  deterministic_best={deterministic_best_action}\")\n",
    "                return best_action\n",
    "\n",
    "        # Bounded rationality: sample action using a softmax over utilities\n",
    "        # (higher beta => closer to argmax; lower beta => more exploratory)\n",
    "        max_u    = max(utilities.values())\n",
    "        exp_vals = {a: np.exp(self.beta * (u - max_u)) for a, u in utilities.items()}\n",
    "        Z        = sum(exp_vals.values())\n",
    "        if Z <= 0:\n",
    "            # Fallback to deterministic NORMAL if something goes wrong numerically\n",
    "            best_action  = 'NORMAL'\n",
    "            best_utility = utilities.get('NORMAL', 0.0)\n",
    "        else:\n",
    "            probs          = {a: v / Z for a, v in exp_vals.items()}\n",
    "            actions, weights = zip(*probs.items())\n",
    "            best_action    = np.random.choice(actions, p=weights)\n",
    "            best_utility   = utilities[best_action]\n",
    "\n",
    "        self.current_action = best_action\n",
    "        self.utility_history.append(best_utility)\n",
    "        self.action_history.append(best_action)\n",
    "\n",
    "        # === DEBUG: always show a heartbeat for early timesteps ===\n",
    "        \"\"\"if self.time <= 5:\n",
    "            print(f\"[DEBUG][uid={self.uid}] t={self.time} choose_action()\")\n",
    "            print(f\"  type={self.type.name}, last_detection={last_detection}, p_mal={p_mal:.3f}\")\n",
    "            print(f\"  utilities={{k: round(v,3) for k,v in utilities.items()}}\")\n",
    "            print(f\"  deterministic_best_action={deterministic_best_action}\")\n",
    "            print(f\"  sampled_action={best_action}, beta={self.beta:.2f}\")\"\"\"\n",
    "\n",
    "        # === DEBUG: classify EXFIL behavior after softmax ===\n",
    "        if self.type == UserType.MALICIOUS and ('EXFILTRATE' in utilities):\n",
    "            if deterministic_best_action == 'EXFILTRATE' and best_action == 'EXFILTRATE':\n",
    "                print(f\"[DEBUG][uid={self.uid}] RATIONAL EXFIL\")\n",
    "                print(f\"  t={self.time}, p_mal={p_mal:.3f}, beta={self.beta:.2f}\")\n",
    "                print(f\"  U_exfil={exfil_utility:.3f}, U_best={deterministic_best_utility:.3f}\")\n",
    "            elif deterministic_best_action == 'EXFILTRATE' and best_action != 'EXFILTRATE':\n",
    "                print(f\"[DEBUG][uid={self.uid}] SKIPPED EXFIL (bounded rationality)\")\n",
    "                print(f\"  t={self.time}, p_mal={p_mal:.3f}, beta={self.beta:.2f}\")\n",
    "                print(f\"  U_exfil={exfil_utility:.3f}, U_best={deterministic_best_utility:.3f}\")\n",
    "                print(f\"  chosen={best_action}\")\n",
    "            elif deterministic_best_action != 'EXFILTRATE' and best_action == 'EXFILTRATE':\n",
    "                print(f\"[DEBUG][uid={self.uid}] IRRATIONAL / GREEDY EXFIL\")\n",
    "                print(f\"  t={self.time}, p_mal={p_mal:.3f}, beta={self.beta:.2f}\")\n",
    "                print(f\"  U_exfil={exfil_utility:.3f}, U_best={deterministic_best_utility:.3f}\")\n",
    "                print(f\"  deterministic_best={deterministic_best_action}\")\n",
    "\n",
    "        # Existing detailed debug for non-normal actions (kept intact)\n",
    "        if self.type != UserType.LOYAL and best_action != 'NORMAL':\n",
    "            certified = (p_mal < 0.3)\n",
    "            print(f\"  AGENT DEBUG: User {self.uid} ({self.type.name}) Decision\")\n",
    "            print(f\"    Current p_mal: {p_mal:.3f}\")\n",
    "            print(f\"    Last detection: {last_detection}\")\n",
    "            print(f\"    Chosen action: {best_action}\")\n",
    "            print(f\"    Utility: {best_utility:.3f}\")\n",
    "            print(f\"    Certified: {certified}\")\n",
    "\n",
    "        return best_action\n",
    "    \n",
    "    def generate_strategic_signals(self, base_signals: np.ndarray, action: str) -> np.ndarray:\n",
    "        \"\"\"Modify signals based on chosen action\"\"\"\n",
    "        signals = base_signals.copy()\n",
    "        \n",
    "        # Apply action-specific signal modifications\n",
    "        if action == 'RECON':\n",
    "            # Boost reconnaissance-related signals\n",
    "            for name, meta in self.committee.dbn.channels.items():\n",
    "                if 'file' in name.lower() or 'recon' in name.lower():\n",
    "                    idx = meta.index\n",
    "                    signals[idx] = np.clip(signals[idx] * 1.5, 0.0, 1.0)\n",
    "                    \n",
    "        elif action == 'WEAPONIZE':\n",
    "            # Boost privilege-related signals\n",
    "            for name, meta in self.committee.dbn.channels.items():\n",
    "                if 'role' in name.lower() or 'priv' in name.lower():\n",
    "                    idx = meta.index\n",
    "                    signals[idx] = np.clip(signals[idx] * 1.8, 0.0, 1.0)\n",
    "                    \n",
    "        elif action == 'EXFILTRATE':\n",
    "            # Boost exfiltration-related signals\n",
    "            for name, meta in self.committee.dbn.channels.items():\n",
    "                if 'exfil' in name.lower() or 'email' in name.lower():\n",
    "                    idx = meta.index\n",
    "                    signals[idx] = np.clip(signals[idx] * 2.0, 0.0, 1.0)\n",
    "        \n",
    "        return signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82bb63ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 4. BYZANTINE COMMITTEE (UPDATED WITH GAME THEORY)\n",
    "# ============================================================================\n",
    "\n",
    "class ByzantineCommittee:\n",
    "    def __init__(self, channels, n_members=5, f_traitors=1):\n",
    "        self.dbn = CausalDependencyDBN(channels)\n",
    "        self.n_members = n_members\n",
    "        self.f_traitors = f_traitors\n",
    "        self.gamma = 0.15 # SACC Clipping Bound\n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #1: Adaptive Detection Thresholds (Lower for early detection)\n",
    "        # ====================================================================\n",
    "        self.detection_threshold_flag = 0.75      # Flag (LOWERED from 1.0)\n",
    "        self.detection_threshold_escalate = 1.66  # Escalate (LOWERED from 2.0)\n",
    "        self.detection_threshold_suspend = 2.5   # Suspend (LOWERED from 3.0)\n",
    "        \n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #2: Faster Belief Convergence (Higher learning rate)\n",
    "        # ====================================================================\n",
    "        self.belief_learning_rate = 1.25  # Accelerated updates (was ~1.0)\n",
    "        \n",
    "        self.user_beliefs = {}\n",
    "        self.belief_history = {}\n",
    "        self.user_agents = {}  # NEW: Store game-theoretic agents\n",
    "        self.last_detection = {}  # NEW: Track detection status for utility\n",
    "        \n",
    "        self.transitions = {\n",
    "            UserType.LOYAL: {UserType.LOYAL: 0.99, UserType.DISGRUNTLED: 0.01, UserType.MALICIOUS: 0.0},\n",
    "            UserType.DISGRUNTLED: {UserType.LOYAL: 0.05, UserType.DISGRUNTLED: 0.90, UserType.MALICIOUS: 0.05},\n",
    "            UserType.MALICIOUS: {UserType.LOYAL: 0.0, UserType.DISGRUNTLED: 0.0, UserType.MALICIOUS: 1.0}\n",
    "        }\n",
    "\n",
    "    def initialize_user(self, uid, user_type=UserType.LOYAL):\n",
    "        self.user_beliefs[uid] = {UserType.LOYAL: 0.9, UserType.DISGRUNTLED: 0.09, UserType.MALICIOUS: 0.01}\n",
    "        self.belief_history[uid] = {\"system\": [], \"anchor\": [], \"byzantine\": [], \"raw_mean\": []}\n",
    "        self.last_detection[uid] = 'normal'\n",
    "        \n",
    "        # NEW: Initialize game-theoretic agent\n",
    "        self.user_agents[uid] = UserAgent(uid, user_type, self)\n",
    "\n",
    "    def _bayes_update(self, prior, signals):\n",
    "        pred = {t: sum(prior[s] * self.transitions[s][t] for s in UserType) for t in UserType}\n",
    "        log_likes = {t: self.dbn.compute_log_likelihood(signals, t) for t in UserType}\n",
    "        max_l = max(log_likes.values())\n",
    "        likes = {t: np.exp(l - max_l) for t, l in log_likes.items()}\n",
    "        post_un = {t: pred[t] * likes[t] for t in UserType}\n",
    "        norm = sum(post_un.values()) or 1e-9\n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #5: Signal-Weighted Bayesian Updates\n",
    "        # Apply higher weight to exfiltration signals (email, exfil)\n",
    "        # ====================================================================\n",
    "        # Apply learning rate acceleration and signal weights to posterior\n",
    "        post_weighted = {}\n",
    "        for t in UserType:\n",
    "            weighted_val = v = post_un[t]\n",
    "            # Amplify malicious belief if high-confidence exfil signals detected\n",
    "            if t == UserType.MALICIOUS and np.max(signals) > 0.7:\n",
    "                weighted_val = v * (1.0 + self.belief_learning_rate * 0.3)\n",
    "            post_weighted[t] = weighted_val\n",
    "        \n",
    "        norm = sum(post_weighted.values()) or 1e-9\n",
    "        return {t: v/norm for t, v in post_weighted.items()}\n",
    "\n",
    "    def certify(self, uid, signals):\n",
    "        if uid not in self.user_beliefs: \n",
    "            self.initialize_user(uid)\n",
    "        \n",
    "        # NEW: Let user agent choose strategic action\n",
    "        if uid in self.user_agents:\n",
    "            agent = self.user_agents[uid]\n",
    "            action = agent.choose_action(self.user_beliefs[uid], self.last_detection[uid])\n",
    "            \n",
    "            # Modify signals based on chosen action\n",
    "            signals = agent.generate_strategic_signals(signals, action)\n",
    "        \n",
    "        # 1. Anchor (Truth)\n",
    "        anchor_dist = self._bayes_update(self.user_beliefs[uid], signals)\n",
    "        anchor_mal = anchor_dist[UserType.MALICIOUS]\n",
    "        \n",
    "        # 2. Honest Reports\n",
    "        reports = [np.clip(anchor_mal + random.uniform(-0.03, 0.03), 0, 1) for _ in range(self.n_members - self.f_traitors)]\n",
    "        \n",
    "        # 3. Traitor Reports\n",
    "        # Visualization User (0): Aggressive suppression to visualize the gap\n",
    "        # Others: \"Little is Enough\" attack to evade clipping\n",
    "        if uid == 0:\n",
    "            traitor_val = 0.05\n",
    "        else:\n",
    "            traitor_val = max(0.0, anchor_mal - 0.25)\n",
    "            \n",
    "        reports.extend([traitor_val] * self.f_traitors)\n",
    "        \n",
    "        # 4. SACC Aggregation\n",
    "        clipped = []\n",
    "        for r in reports:\n",
    "            diff = r - anchor_mal\n",
    "            if abs(diff) > self.gamma:\n",
    "                clipped.append(anchor_mal + (np.sign(diff) * self.gamma))\n",
    "            else:\n",
    "                clipped.append(r)\n",
    "        \n",
    "        robust_mal = np.mean(clipped)\n",
    "        \n",
    "        # Update State\n",
    "        rem = 1.0 - robust_mal\n",
    "        self.user_beliefs[uid] = {\n",
    "            UserType.LOYAL: rem * 0.9, UserType.DISGRUNTLED: rem * 0.1, UserType.MALICIOUS: robust_mal\n",
    "        }\n",
    "        \n",
    "        # Log History\n",
    "        h = self.belief_history[uid]\n",
    "        h[\"system\"].append(robust_mal)\n",
    "        h[\"anchor\"].append(anchor_mal)\n",
    "        h[\"byzantine\"].append(traitor_val)\n",
    "        h[\"raw_mean\"].append(np.mean(reports))\n",
    "        \n",
    "\n",
    "        # ====================================================================\n",
    "        # IMPROVEMENT #4: Multi-Stage Detection (With PERMANENT DISABLE Latch)\n",
    "        # ====================================================================\n",
    "        threat_score = robust_mal * 4.0  # Scale to ITS range [0, 4]\n",
    "        \n",
    "        # 1. Retrieve previous state\n",
    "        previous_status = self.last_detection.get(uid, 'normal')\n",
    "        \n",
    "        # 2. Apply Latch Logic: If previously suspended, STAY suspended (Disabled)\n",
    "        if previous_status == 'SUSPEND':\n",
    "            detection_status = 'SUSPEND'\n",
    "        # 3. Otherwise, apply standard thresholds\n",
    "        elif threat_score >= self.detection_threshold_suspend:\n",
    "            detection_status = 'SUSPEND'\n",
    "        elif threat_score >= self.detection_threshold_escalate:\n",
    "            detection_status = 'ESCALATE'\n",
    "        elif threat_score >= self.detection_threshold_flag:\n",
    "            detection_status = 'FLAG'\n",
    "        else:\n",
    "            detection_status = 'normal'\n",
    "        \n",
    "        # Store detection metadata for analysis\n",
    "        self.user_beliefs[uid]['_threat_score'] = threat_score\n",
    "        self.user_beliefs[uid]['_detection_status'] = detection_status\n",
    "        self.last_detection[uid] = detection_status\n",
    "\n",
    "        return robust_mal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "663c2ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 5. SIMULATION LOOP (Hybrid with Game Theory)\n",
    "# ============================================================================\n",
    "class ByzantineSimulation:\n",
    "    def __init__(self, policy_file):\n",
    "        self.channels = self._load_policies(policy_file)\n",
    "        self.committee = ByzantineCommittee(self.channels)\n",
    "        self.n_channels = len(self.channels)\n",
    "\n",
    "    def _load_policies(self, fpath):\n",
    "        with open(fpath) as f: policies = json.load(f)\n",
    "        temp = {}\n",
    "        for p in policies:\n",
    "            cn = p['signal_channel']\n",
    "            if cn not in temp: \n",
    "                temp[cn] = ChannelMetadata(len(temp), cn, p.get('category', 'Activity'), p.get('severity', 0.5))\n",
    "        return temp\n",
    "\n",
    "    def _generate_signals(self, u_type, t, is_malicious, uid):\n",
    "        signals = np.random.beta(2, 12, size=self.n_channels)\n",
    "\n",
    "        # DEBUG: Print signal generation for user 0 (malicious) and 99 (loyal)\n",
    "        \"\"\"if uid in [0, 99] and t == 0:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"DEBUG: User {uid} ({'MALICIOUS' if is_malicious else 'LOYAL'}) Signal Generation Start\")\n",
    "            print(f\"Initial signal values: {[f'{s:.3f}' for s in signals]}\")\n",
    "            print(f\"User type: {u_type.name}\")\n",
    "            print(f\"{'='*60}\\n\")\"\"\"\n",
    "\n",
    "        if is_malicious:\n",
    "            # A. VISUALIZATION USER (0) - Now uses game theory\n",
    "            if uid == 0:\n",
    "                # Initialize malicious agent for user 0 at t=0\n",
    "                if t == 0 and uid not in self.committee.user_agents:\n",
    "                    self.committee.initialize_user(uid, UserType.MALICIOUS)\n",
    "                    print(f\"DEBUG: User {uid} initialized as MALICIOUS agent\")\n",
    "                    \n",
    "                if t > 30:  # Start strategic attacks after t=30\n",
    "                    # Strategic actions will be chosen by UserAgent in certify()\n",
    "                    # Base malicious signals\n",
    "                    for m in self.channels.values():\n",
    "                        signals[m.index] = np.clip(np.random.beta(8, 3), 0.01, 0.99)\n",
    "                    return signals\n",
    "                \n",
    "            # B. OTHER MALICIOUS USERS (Strategic)\n",
    "            elif t > 30:\n",
    "                # Initialize malicious agent if not already\n",
    "                if uid not in self.committee.user_agents:\n",
    "                    self.committee.initialize_user(uid, UserType.MALICIOUS)\n",
    "                    print(f\"DEBUG: User {uid} initialized as MALICIOUS agent\")\n",
    "\n",
    "                # Strategic actions chosen in certify()\n",
    "                for m in self.channels.values():\n",
    "                    if random.random() < 0.4:  # 40% chance of boosted signals\n",
    "                        signals[m.index] = np.clip(np.random.beta(6, 4), 0.01, 0.99)\n",
    "        \n",
    "        elif u_type == UserType.DISGRUNTLED:\n",
    "            # Strategic disgruntled users\n",
    "            if uid not in self.committee.user_agents:\n",
    "                self.committee.initialize_user(uid, UserType.DISGRUNTLED)\n",
    "                \n",
    "            n_spikes = random.randint(1, 3)\n",
    "            indices = random.sample(range(self.n_channels), n_spikes)\n",
    "            for idx in indices:\n",
    "                signals[idx] = np.clip(np.random.beta(4, 6), 0.01, 0.99)\n",
    "                \n",
    "        elif u_type == UserType.LOYAL:\n",
    "            # Initialize loyal agent\n",
    "            if uid not in self.committee.user_agents:\n",
    "                self.committee.initialize_user(uid, UserType.LOYAL)\n",
    "                print(f\"DEBUG: User {uid} initialized as LOYAL agent\")\n",
    "            \n",
    "            if random.random() < 0.02:  # 2% of benign timesteps\n",
    "                # Legitimate suspicious activity\n",
    "                idx = random.randint(0, len(self.channels)-1)\n",
    "                signals[idx] = np.clip(np.random.beta(15, 3), 0.01, 0.99)\n",
    "                if uid in [0, 99]:\n",
    "                    print(f\"DEBUG: User {uid} generated legitimate suspicious activity at channel {idx}\")\n",
    "            elif random.random() < 0.02:\n",
    "                idx = random.randint(0, self.n_channels-1)\n",
    "                signals[idx] = 0.85\n",
    "                #print(f\"DEBUG: User {uid} generated high signal at channel {idx}\")\n",
    "\n",
    "        return np.clip(signals, 0.01, 0.99)\n",
    "\n",
    "    def run(self, n_users=100, pct_mal=0.15, horizon=90):\n",
    "        n_mal = int(n_users * pct_mal)\n",
    "        results = {\"detected\": [], \"false_positives\": [], \"undetected\": [], \"hist\": {}}\n",
    "        \n",
    "        \n",
    "        # DEBUG: Start tracking\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"DEBUG: STARTING SIMULATION\")\n",
    "        print(f\"Tracking User 0 (Malicious) and User 99 (Loyal)\")\n",
    "        print(f\"Total users: {n_users}, Malicious users: {n_mal}\")\n",
    "        print(f\"{'#'*60}\\n\")\n",
    "\n",
    "        for uid in range(n_users):\n",
    "            is_mal = uid < n_mal\n",
    "            u_type = UserType.LOYAL\n",
    "            self.committee.initialize_user(uid)\n",
    "            results[\"hist\"][uid] = {\"type\": [], \"causal_score\": [], \"action\": [], \"utility\": []}\n",
    "            detected = False\n",
    "            \"\"\"\n",
    "            # DEBUG: User initialization message\n",
    "            if uid in [77]:\n",
    "                print(f\"\\n{'='*40}\")\n",
    "                print(f\"DEBUG: User {uid} Journey Begin\")\n",
    "                print(f\"User Type: {'MALICIOUS' if is_mal else 'LOYAL'}\")\n",
    "                print(f\"Initial Beliefs: {self.committee.user_beliefs[uid]}\")\n",
    "                print(f\"{'='*40}\\n\")\n",
    "            \"\"\"\n",
    "            \n",
    "            for t in range(horizon):\n",
    "                if uid == 0:\n",
    "                    # User 0: Transition from loyal to malicious via game theory\n",
    "                    if t > TRIGGER_DAY: \n",
    "                        u_type = UserType.MALICIOUS\n",
    "                        if t == 31 and uid in [0, 99]:\n",
    "                            print(f\"\\nDEBUG: User {uid} transitioned to MALICIOUS at t={t}\")\n",
    "                    elif t > TRIGGER_DAY - 10: \n",
    "                        u_type = UserType.DISGRUNTLED\n",
    "                        if t == 21 and uid in [0, 99]:\n",
    "                            print(f\"\\nDEBUG: User {uid} transitioned to DISGRUNTLED at t={t}\")\n",
    "                else:\n",
    "                    if is_mal and t > TRIGGER_DAY+10: \n",
    "                        u_type = UserType.MALICIOUS\n",
    "                    elif not is_mal and t > TRIGGER_DAY and random.random() < 0.04: \n",
    "                        u_type = UserType.DISGRUNTLED\n",
    "                \n",
    "                results[\"hist\"][uid][\"type\"].append(u_type.value)\n",
    "                signals = self._generate_signals(u_type, t, is_mal, uid)\n",
    "                p_mal = self.committee.certify(uid, signals)\n",
    "                threat = self.committee.dbn.compute_threat_score(signals)\n",
    "                \n",
    "                # Track action and utility for strategic users\n",
    "                if uid in self.committee.user_agents:\n",
    "                    agent = self.committee.user_agents[uid]\n",
    "                    results[\"hist\"][uid][\"action\"].append(agent.current_action)\n",
    "                    results[\"hist\"][uid][\"utility\"].append(agent.utility_history[-1] if agent.utility_history else 0)\n",
    "                else:\n",
    "                    results[\"hist\"][uid][\"action\"].append('NORMAL')\n",
    "                    results[\"hist\"][uid][\"utility\"].append(0)\n",
    "                \n",
    "                results[\"hist\"][uid][\"causal_score\"].append(threat)\n",
    "                risk = (p_mal * P_MAL) + (threat * THREAT)\n",
    "\n",
    "                # DEBUG: Print detailed info for tracked users at key timesteps\n",
    "                \"\"\"\n",
    "                if uid in [0, 99]:\n",
    "                    if t in [0, 10, 20, 30, 40, 50, 60, 70, 80, 89] or detected:\n",
    "                        agent = self.committee.user_agents.get(uid)\n",
    "                        anchor_mal = self.committee.belief_history[uid][\"anchor\"][-1] if self.committee.belief_history[uid][\"anchor\"] else 0\n",
    "                        traitor_val = self.committee.belief_history[uid][\"byzantine\"][-1] if self.committee.belief_history[uid][\"byzantine\"] else 0\n",
    "                        \n",
    "                        print(f\"\\nDEBUG t={t:3d}: User {uid:3d} ({'MAL' if is_mal else 'LOY'})\")\n",
    "                        print(f\"  Type: {u_type.name:12s} | Action: {agent.current_action if agent else 'NORMAL':10s}\")\n",
    "                        print(f\"  Signals max: {np.max(signals):.3f} | Threat score: {threat:.3f}\")\n",
    "                        print(f\"  Beliefs - Anchor: {anchor_mal:.3f} | Traitor: {traitor_val:.3f} | System: {p_mal:.3f}\")\n",
    "                        print(f\"  Risk: {risk:.3f} | Detection status: {self.committee.last_detection[uid]}\")\n",
    "                        if agent and agent.utility_history:\n",
    "                            print(f\"  Utility: {agent.utility_history[-1]:.3f}\")\n",
    "                \"\"\"\n",
    "                \n",
    "                if risk > THRESHOLD and not detected:\n",
    "                    detected = True\n",
    "                    if is_mal: \n",
    "                        results[\"detected\"].append(uid)\n",
    "                        if uid in [0, 99]:\n",
    "                            print(f\"\\n{'!'*60}\")\n",
    "                            print(f\"DEBUG: User {uid} DETECTED as MALICIOUS at t={t}\")\n",
    "                            print(f\"Risk: {risk:.3f} > Threshold: {THRESHOLD}\")\n",
    "                            print(f\"Detection status: {self.committee.last_detection[uid]}\")\n",
    "                            print(f\"{'!'*60}\\n\")\n",
    "                    else: \n",
    "                        results[\"false_positives\"].append(uid)\n",
    "                        if uid in [0, 99]:\n",
    "                            print(f\"\\n{'!'*60}\")\n",
    "                            print(f\"DEBUG: FALSE POSITIVE - User {uid} flagged at t={t}\")\n",
    "                            print(f\"Risk: {risk:.3f} > Threshold: {THRESHOLD}\")\n",
    "                            print(f\"Detection status: {self.committee.last_detection[uid]}\")\n",
    "                            print(f\"{'!'*60}\\n\")\n",
    "            \n",
    "            if is_mal and not detected: \n",
    "                results[\"undetected\"].append(uid)\n",
    "                if uid in [0, 99]:\n",
    "                    print(f\"\\n{'*'*60}\")\n",
    "                    print(f\"DEBUG: User {uid} NOT DETECTED (False Negative)\")\n",
    "                    print(f\"Final risk: {risk:.3f}\")\n",
    "                    print(f\"Final detection status: {self.committee.last_detection[uid]}\")\n",
    "                    print(f\"{'*'*60}\\n\")\n",
    "            \n",
    "            # DEBUG: Final summary for tracked users\n",
    "            if uid in [0, 99]:\n",
    "                print(f\"\\n{'='*40}\")\n",
    "                print(f\"DEBUG: User {uid} Journey Complete\")\n",
    "                print(f\"Total timesteps: {horizon}\")\n",
    "                print(f\"Final Beliefs: {self.committee.user_beliefs[uid]}\")\n",
    "                print(f\"Detection status: {self.committee.last_detection[uid]}\")\n",
    "                print(f\"Detected: {detected}\")\n",
    "                print(f\"{'='*40}\\n\")\n",
    "\n",
    "        # DEBUG: Final simulation summary\n",
    "        print(f\"\\n{'#'*60}\")\n",
    "        print(f\"DEBUG: SIMULATION COMPLETE\")\n",
    "        print(f\"Total users: {n_users}\")\n",
    "        print(f\"True Positives: {len(results['detected'])}\")\n",
    "        print(f\"False Positives: {len(results['false_positives'])}\")\n",
    "        print(f\"False Negatives: {len(results['undetected'])}\")\n",
    "        print(f\"Tracked User 0 (Malicious): {'DETECTED' if 0 in results['detected'] else 'NOT DETECTED'}\")\n",
    "        print(f\"Tracked User 99 (Loyal): {'FALSE POSITIVE' if 99 in results['false_positives'] else 'NOT DETECTED'}\")\n",
    "        print(f\"{'#'*60}\\n\")\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e3ef857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# 6. VISUALIZATION (UPDATED WITH GAME THEORY)\n",
    "# ============================================================================\n",
    "\n",
    "class FullVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_combined_dashboard(res, committee, n_users, uid_malicious=0):\n",
    "        \"\"\"Combined dashboard with game theory visualization.\"\"\"\n",
    "        fig = plt.figure(figsize=(20, 16))\n",
    "        gs = gridspec.GridSpec(3, 2, hspace=0.35, wspace=0.3)\n",
    "\n",
    "        # Panel 1: Type Evolution (Top-Left)\n",
    "        ax1 = plt.subplot(gs[0, 0])\n",
    "        ax1.set_title(\"1. User Type Evolution (Ground Truth)\", fontweight='bold', fontsize=12)\n",
    "        ax1.set_yticks([0, 1, 2])\n",
    "        ax1.set_yticklabels(['LOY', 'DIS', 'MAL'])\n",
    "        ax1.set_xlabel(\"Time Step\")\n",
    "        for uid in list(res[\"detected\"][:5]) + list(res[\"undetected\"][:5]):\n",
    "            color = 'red' if uid in res[\"detected\"] else 'orange'\n",
    "            ax1.plot(res[\"hist\"][uid][\"type\"], color=color, alpha=0.6, linewidth=1.5)\n",
    "        for uid in range(n_users - 5, n_users):\n",
    "            ax1.plot(res[\"hist\"][uid][\"type\"], color='green', alpha=0.3, linewidth=0.8)\n",
    "        ax1.grid(True, alpha=0.2)\n",
    "\n",
    "        # Panel 2: Game-Theoretic Actions (Top-Right)\n",
    "        ax2 = plt.subplot(gs[0, 1])\n",
    "        ax2.set_title(\"2. Game-Theoretic User Actions\", fontweight='bold', fontsize=12)\n",
    "        ax2.set_xlabel(\"Time Step\")\n",
    "        ax2.set_ylabel(\"Action\")\n",
    "        \n",
    "        # Map actions to numerical values for plotting\n",
    "        action_map = {'NORMAL': 0, 'RECON': 1, 'WEAPONIZE': 2, 'EXFILTRATE': 3}\n",
    "        \n",
    "        for uid in range(min(5, n_users)):  # Show first 3 users\n",
    "            if 'action' in res[\"hist\"][uid] and res[\"hist\"][uid][\"action\"]:\n",
    "                actions_numeric = [action_map.get(a, 0) for a in res[\"hist\"][uid][\"action\"]]\n",
    "                ax2.plot(actions_numeric, alpha=0.7, linewidth=1.5, \n",
    "                         label=f'User {uid}' if uid in [0,1,2,3,4] else '')\n",
    "        \n",
    "        ax2.set_yticks([0, 1, 2, 3])\n",
    "        ax2.set_yticklabels(['NORM', 'RECON', 'WEAP', 'EXFIL'])\n",
    "        ax2.legend(loc='best', fontsize=9)\n",
    "        ax2.grid(True, alpha=0.2)\n",
    "\n",
    "        # Panel 3: User Utility (Middle-Left)\n",
    "        ax3 = plt.subplot(gs[1, 0])\n",
    "        ax3.set_title(\"3. User Utility Optimization\", fontweight='bold', fontsize=12)\n",
    "        ax3.set_xlabel(\"Time Step\")\n",
    "        ax3.set_ylabel(\"Utility U_byz\")\n",
    "        \n",
    "        for uid in range(min(5, n_users)):\n",
    "            if 'utility' in res[\"hist\"][uid] and res[\"hist\"][uid][\"utility\"]:\n",
    "                ax3.plot(res[\"hist\"][uid][\"utility\"], alpha=0.7, linewidth=1.5,\n",
    "                         label=f'User {uid} (MAL)' if uid in res[\"detected\"] else f'User {uid}')\n",
    "        \n",
    "        ax3.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "        ax3.legend(loc='best', fontsize=9)\n",
    "        ax3.grid(True, alpha=0.2)\n",
    "\n",
    "        # Panel 4: Causal Kill Chain Evidence (Middle-Right)\n",
    "        ax4 = plt.subplot(gs[1, 1])\n",
    "        ax4.set_title(\"4. Causal Kill Chain Evidence\", fontweight='bold', fontsize=12)\n",
    "        ax4.set_xlabel(\"Time Step\")\n",
    "        ax4.set_ylabel(\"Causal Score\")\n",
    "        for uid in res[\"hist\"]:\n",
    "            scores = res[\"hist\"][uid][\"causal_score\"]\n",
    "            if uid in res[\"detected\"][:5]:\n",
    "                ax4.plot(scores, color='red', alpha=0.5, linewidth=1.5)\n",
    "            elif uid > n_users - 5:\n",
    "                ax4.plot(scores, color='green', alpha=0.3, linewidth=0.8)\n",
    "        ax4.grid(True, alpha=0.2)\n",
    "\n",
    "        # Panel 5: System Belief Convergence (Bottom-Left)\n",
    "        ax5 = plt.subplot(gs[2, 0])\n",
    "        ax5.set_title(\"5. System Belief Convergence\", fontweight='bold', fontsize=12)\n",
    "        ax5.set_xlabel(\"Time Step\")\n",
    "        ax5.set_ylabel(\"Belief Score\")\n",
    "        ax5.axhline(0.75, color='black', linestyle='--', linewidth=1, label='Detection Threshold')\n",
    "        for uid in res[\"hist\"]:\n",
    "            beliefs = committee.belief_history[uid][\"system\"]\n",
    "            if uid in res[\"detected\"][:5]:\n",
    "                ax5.plot(beliefs, color='red', alpha=0.7, linewidth=1.5)\n",
    "            elif uid in res[\"false_positives\"][:5]:\n",
    "                ax5.plot(beliefs, color='blue', alpha=0.6, linewidth=1.2)\n",
    "            elif uid > n_users - 5:\n",
    "                ax5.plot(beliefs, color='green', alpha=0.2, linewidth=0.8)\n",
    "        ax5.legend(loc='best', fontsize=9)\n",
    "        ax5.grid(True, alpha=0.2)\n",
    "\n",
    "        # Panel 6: SACC Robustness (Bottom-Right)\n",
    "        ax6 = plt.subplot(gs[2, 1])\n",
    "        ax6.set_title(\"6. SACC Defense - Byzantine Resilience\", fontweight='bold', fontsize=12)\n",
    "        ax6.set_xlabel(\"Time Step\")\n",
    "        ax6.set_ylabel(\"Belief Score\")\n",
    "\n",
    "        hist = committee.belief_history[uid_malicious]\n",
    "        ax6.plot(hist[\"anchor\"], color='blue', linestyle='--', label='Anchor (Truth)', linewidth=2)\n",
    "        ax6.plot(hist[\"byzantine\"], color='red', linestyle=':', label='Traitor (Suppression)', linewidth=1.5)\n",
    "        ax6.plot(hist[\"raw_mean\"], color='orange', linestyle='-.', label='Naive Mean', alpha=0.7, linewidth=1.5)\n",
    "        ax6.plot(hist[\"system\"], color='green', label='SACC Belief (Robust)', linewidth=2.5)\n",
    "        ax6.axhline(0.75, color='grey', linestyle='--', alpha=0.5)\n",
    "        ax6.fill_between(range(len(hist[\"system\"])), hist[\"raw_mean\"], hist[\"system\"], \n",
    "                        color='green', alpha=0.1, label='SACC Protection')\n",
    "        ax6.legend(loc='best', fontsize=9)\n",
    "        ax6.grid(True, alpha=0.2)\n",
    "\n",
    "        plt.suptitle(\"Game-Theoretic Byzantine-Resilient IAM Certification System\", \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(\"game_theory_dashboard.png\", dpi=100, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # Print metrics\n",
    "        tp = len(res[\"detected\"])\n",
    "        fp = len(res[\"false_positives\"])\n",
    "        fn = len(res[\"undetected\"])\n",
    "        prec = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        rec = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GAME-THEORETIC DETECTION METRICS\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total Users:          {n_users}\")\n",
    "        print(f\"True Positives (TP):  {tp}\")\n",
    "        print(f\"False Positives (FP): {fp}\")\n",
    "        print(f\"False Negatives (FN): {fn}\")\n",
    "        print(f\"\\nPrecision:  {prec:.4f}\")\n",
    "        print(f\"Recall:     {rec:.4f}\")\n",
    "        print(f\"F1 Score:   {f1:.4f}\")\n",
    "        \n",
    "        # Print game theory statistics\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"GAME THEORY ANALYSIS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Analyze strategic behavior\n",
    "        strategic_users = 0\n",
    "        total_actions = 0\n",
    "        action_counts = {'NORMAL': 0, 'RECON': 0, 'WEAPONIZE': 0, 'EXFILTRATE': 0}\n",
    "        \n",
    "        for uid in range(n_users):\n",
    "            if 'action' in res[\"hist\"][uid]:\n",
    "                strategic_users += 1\n",
    "                for action in res[\"hist\"][uid][\"action\"]:\n",
    "                    action_counts[action] += 1\n",
    "                    total_actions += 1\n",
    "        \n",
    "        print(f\"Strategic Users: {strategic_users}\")\n",
    "        print(f\"Total Actions: {total_actions}\")\n",
    "        print(\"\\nAction Distribution:\")\n",
    "        for action, count in action_counts.items():\n",
    "            percentage = (count / total_actions * 100) if total_actions > 0 else 0\n",
    "            print(f\"  {action}: {count} ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(\"=\"*70 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defecd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RUNNING HYBRID SIMULATION\n",
      "============================================================\n",
      "\n",
      "############################################################\n",
      "DEBUG: STARTING SIMULATION\n",
      "Tracking User 0 (Malicious) and User 99 (Loyal)\n",
      "Total users: 100, Malicious users: 25\n",
      "############################################################\n",
      "\n",
      "\n",
      "DEBUG: User 0 transitioned to MALICIOUS at t=31\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "DEBUG: User 0 DETECTED as MALICIOUS at t=31\n",
      "Risk: 1.345 > Threshold: 0.5\n",
      "Detection status: SUSPEND\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "\n",
      "========================================\n",
      "DEBUG: User 0 Journey Complete\n",
      "Total timesteps: 90\n",
      "Final Beliefs: {<UserType.LOYAL: 0>: np.float64(0.032688522292278345), <UserType.DISGRUNTLED: 1>: np.float64(0.003632058032475372), <UserType.MALICIOUS: 2>: np.float64(0.9636794196752463), '_threat_score': np.float64(3.854717678700985), '_detection_status': 'SUSPEND'}\n",
      "Detection status: SUSPEND\n",
      "Detected: True\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(\"policies.json\"):\n",
    "        with open(\"policies.json\", \"w\") as f:\n",
    "            json.dump([\n",
    "                {\"signal_channel\": \"s_logon\", \"category\": \"Access\", \"severity\": 0.6},\n",
    "                {\"signal_channel\": \"s_file\", \"category\": \"Reconnaissance\", \"severity\": 0.7},\n",
    "                {\"signal_channel\": \"s_role\", \"category\": \"Privilege\", \"severity\": 0.9},\n",
    "                {\"signal_channel\": \"s_exfil\", \"category\": \"Exfiltration\", \"severity\": 0.8}\n",
    "            ], f)\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"RUNNING HYBRID SIMULATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    NUM_USERS = 100\n",
    "\n",
    "    sim = ByzantineSimulation(\"policies.json\")\n",
    "    results = sim.run(n_users=NUM_USERS, pct_mal=0.25, horizon=90)\n",
    "    \n",
    "    FullVisualizer.plot_combined_dashboard(results, sim.committee, NUM_USERS)\n",
    "    \n",
    "    # Plot SACC Robustness for User 0 (Guaranteed Attacker)\n",
    "    #FullVisualizer.plot_sacc_robustness(sim.committee, 0)\n",
    "        \n",
    "    print(\"\\n✓ Process Complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
